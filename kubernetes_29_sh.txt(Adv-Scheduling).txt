adv schedulling

   node selectors
   Taints and Tolerations
Node Afinity
Pod Affinity & anti Affinity


4 node will deployed

kubectl label node ip-172-20-55-14.ec2.internal disktype=hdd
---

apiVersion: v1
kind: Pod
metadata:
  name: nginx-hdd
  labels:
    env: test
spec:
  containers:
  - name: nginx
    image: nginx
  nodeSelector:
    disktype: hdd

kubectl label node ip-172-20-45-19.ap-south-1.compute.internal env=prod    
kubectl label node ip-172-20-50-107.ap-south-1.compute.internal env=prod
kubectl label node ip-172-20-77-198.ap-south-1.compute.internal  env=dev
kubectl label node ip-172-20-95-210.ap-south-1.compute.internal  env=dev


root@ip-172-31-8-33:~# ^C
root@ip-172-31-8-33:~# ^C
root@ip-172-31-8-33:~# kubectl label node ip-172-20-45-19.ap-south-1.compute.internal env=prod
node/ip-172-20-45-19.ap-south-1.compute.internal labeled
root@ip-172-31-8-33:~# kubectl label node ip-172-20-50-107.ap-south-1.compute.internal env=prod
node/ip-172-20-50-107.ap-south-1.compute.internal labeled
root@ip-172-31-8-33:~# kubectl label node ip-172-20-77-198.ap-south-1.compute.internal  env =dev
error: at least one label update is required
root@ip-172-31-8-33:~# kubectl label node ip-172-20-95-210.ap-south-1.compute.internal  env=dev
node/ip-172-20-95-210.ap-south-1.compute.internal labeled
root@ip-172-31-8-33:~# kubectl label node ip-172-20-77-198.ap-south-1.compute.internal  env=dev
node/ip-172-20-77-198.ap-south-1.compute.internal labeled
root@ip-172-31-8-33:~#


apiVersion: apps/v1
kind: Deployment
metadata:
  name: prod1
  labels:
    app: nginx
spec:
  replicas: 2
  selector:
    matchLabels:
      app: nginx
  template:
    metadata:
      labels:
        app: nginx
    spec:
      containers:
      - name: nginx
        image: nginx:1.14.2
        ports:
        - containerPort: 80
      nodeSelector:
        env: prod
 


root@ip-172-31-8-33:~# echo 'apiVersion: apps/v1
> kind: Deployment
> metadata:
>   name: prod1
>   labels:
      app: nginx
  template:
>     app: nginx
> spec:
>   replicas: 2
>   selector:
>     matchLabels:
>       app: nginx
>   template:
>     metadata:
>       labels:
>         app: nginx
>     spec:
>       containers:
>       - name: nginx
>         image: nginx:1.14.2
>         ports:
>         - containerPort: 80
>       nodeSelector:
>         env: prod
> ' | kubectl create -f -
deployment.apps/prod1 created
root@ip-172-31-8-33:~# kubectl get pods
NAME                    READY   STATUS    RESTARTS   AGE
prod1-85c79f66d-6rfmv   1/1     Running   0          19s
prod1-85c79f66d-r2lrm   1/1     Running   0          19s
root@ip-172-31-8-33:~# kubectl pods -o wide
Error: unknown command "pods" for "kubectl"

Did you mean this?
        logs

Run 'kubectl --help' for usage.
root@ip-172-31-8-33:~# kubectl get pods -o wide
NAME                    READY   STATUS    RESTARTS   AGE   IP           NODE                                           NOMINATED NODE   READINESS GATES
prod1-85c79f66d-6rfmv   1/1     Running   0          48s   100.96.4.3   ip-172-20-50-107.ap-south-1.compute.internal   <none>           <none>
prod1-85c79f66d-r2lrm   1/1     Running   0          48s   100.96.1.3   ip-172-20-45-19.ap-south-1.compute.internal    <none>           <none>
root@ip-172-31-8-33:~#


kubectl get pods -o wide | grep -i dev


root@ip-172-31-8-33:~# kubectl delete deploy --all
deployment.apps "prod1" deleted
root@ip-172-31-8-33:~#



removing labels also

kubectl label node ip-172-20-45-19.ap-south-1.compute.internal env-    
kubectl label node ip-172-20-50-107.ap-south-1.compute.internal env-
kubectl label node ip-172-20-77-198.ap-south-1.compute.internal  env-
kubectl label node ip-172-20-95-210.ap-south-1.compute.internal  env-


root@ip-172-31-8-33:~# kubectl label node ip-172-20-45-19.ap-south-1.compute.internal env-
node/ip-172-20-45-19.ap-south-1.compute.internal labeled
root@ip-172-31-8-33:~# kubectl label node ip-172-20-50-107.ap-south-1.compute.internal env-
node/ip-172-20-50-107.ap-south-1.compute.internal labeled
root@ip-172-31-8-33:~# kubectl label node ip-172-20-77-198.ap-south-1.compute.internal  env-
node/ip-172-20-77-198.ap-south-1.compute.internal labeled
root@ip-172-31-8-33:~# kubectl label node ip-172-20-95-210.ap-south-1.compute.internal  env-
node/ip-172-20-95-210.ap-south-1.compute.internal labeled


-------------------------------------------------------------------------------------------------------------

Taints and tolernts
(nodes)        (pods)
noschedule  ------> pods wont be shared
preferredschedule------>

no excute  ---> will evict/remove pods.



node:1             Node:2                     Node:3           Node:4
Labels             LABELS                        env=dev           env=dev
  env=prod          ENV=PROD

Taint                   Taint
  disktype=ssd:Noschedule      disktype+hdd:Noschedule






kubectl label node ip-172-20-45-19.ap-south-1.compute.internal env=prod    
kubectl label node ip-172-20-50-107.ap-south-1.compute.internal env=prod
kubectl label node ip-172-20-77-198.ap-south-1.compute.internal  env=dev
kubectl label node ip-172-20-95-210.ap-south-1.compute.internal  env=dev


apiVersion: apps/v1
kind: Deployment
metadata:
  name: prod1
  labels:
    app: nginx
spec:
  replicas: 2
  selector:
    matchLabels:
      app: nginx
  template:
    metadata:
      labels:
        app: nginx
    spec:
      containers:
      - name: nginx
        image: nginx:1.14.2
        ports:
        - containerPort: 80
      nodeSelector:
        env: prod

root@ip-172-31-8-33:~# kubectl delete deploy --all
deployment.apps "prod1" deleted

prod1-85c79f66d-7mfmm   1/1     Running   0          88s   100.96.4.4   ip-172-20-50-107.ap-south-1.compute.internal   <none>           <none>
prod1-85c79f66d-qc8m7   1/1     Running   0          88s   100.96.1.4   ip-172-20-45-19.ap-south-1.compute.internal    <none>           <none>
root@ip-172-31-8-33:~#


kubectl taint node ip-172-20-45-19.ap-south-1.compute.internal diskType=ssd:NoSchedule  
kubectl taint node ip-172-20-50-107.ap-south-1.compute.internal diskType=ssd:NoSchedule 


NAME                    READY   STATUS    RESTARTS   AGE
prod1-85c79f66d-jmscf   0/1     Pending   0          45s
prod1-85c79f66d-vl4c6   0/1     Pending   0          45s
root@ip-172-31-8-33:~#


how to delete taint

kubectl taint node ip-172-20-45-19.ap-south-1.compute.internal diskType-  
kubectl taint node ip-172-20-50-107.ap-south-1.compute.internal diskType-


prod1-85c79f66d-jmscf   1/1     Running   0          2m31s
prod1-85c79f66d-vl4c6   1/1     Running   0          2m31s

kubectl taint node ip-172-20-45-19.ap-south-1.compute.internal diskType=ssd:NoExecute  
kubectl taint node ip-172-20-50-107.ap-south-1.compute.internal diskType=ssd:NoExecute 


root@ip-172-31-8-33:~# kubectl  get pods
NAME                    READY   STATUS        RESTARTS   AGE
prod1-85c79f66d-85ghg   0/1     Pending       0          8s
prod1-85c79f66d-jmscf   0/1     Terminating   0          4m25s
prod1-85c79f66d-vl4c6   0/1     Terminating   0          4m25s
prod1-85c79f66d-xpckp   0/1     Pending       0          8s
root@ip-172-31-8-33:~#



kubectl taint node ip-172-20-45-19.ap-south-1.compute.internal diskType-  
kubectl taint node ip-172-20-50-107.ap-south-1.compute.internal diskType-


root@ip-172-31-8-33:~# kubectl taint node ip-172-20-45-19.ap-south-1.compute.internal diskType-
node/ip-172-20-45-19.ap-south-1.compute.internal untainted
root@ip-172-31-8-33:~# kubectl taint node ip-172-20-50-107.ap-south-1.compute.internal diskType-
node/ip-172-20-50-107.ap-south-1.compute.internal untainted



kubectl taint node ip-172-20-45-19.ap-south-1.compute.internal diskType=ssd:NoSchedule  
kubectl taint node ip-172-20-50-107.ap-south-1.compute.internal diskType=hdd:NoSchedule 

apiVersion: apps/v1
kind: Deployment
metadata:
  name: prod1
  labels:
    app: nginx
spec:
  replicas: 2
  selector:
    matchLabels:
      app: nginx
  template:
    metadata:
      labels:
        app: nginx
    spec:
      containers:
      - name: nginx
        image: nginx:1.14.2
        ports:
        - containerPort: 80
      nodeSelector:
        env: prod
      tolerations:
         - key: "diskType"
           operator: "Equal"
           value: "ssd"
           effect: "NoSchedule"


root@ip-172-31-8-33:~# kubectl get pods -o wide
NAME                     READY   STATUS    RESTARTS   AGE   IP            NODE                                          NOMINATED NODE   READINESS GATES
prod1-74f6d8685b-q4xlj   1/1     Running   0          4s    100.96.1.10   ip-172-20-45-19.ap-south-1.compute.internal   <none>           <none>
prod1-74f6d8685b-v6xx2   1/1     Running   0          4s    100.96.1.11   ip-172-20-45-19.ap-south-1.compute.internal   <none>           <none>
root@ip-172-31-8-33:~#



apiVersion: apps/v1
kind: Deployment
metadata:
  name: prod11
  labels:
    app: nginx
spec:
  replicas: 2
  selector:
    matchLabels:
      app: nginx
  template:
    metadata:
      labels:
        app: nginx
    spec:
      containers:
      - name: nginx
        image: nginx:1.14.2
        ports:
        - containerPort: 80
      nodeSelector:
        env: prod
      tolerations:
         - key: "diskType"
           operator: "Equal"
           value: "hdd"
           effect: "NoSchedule"


root@ip-172-31-8-33:~# kubectl get pods -o wide
NAME                      READY   STATUS    RESTARTS   AGE     IP            NODE                                           NOMINATED NODE   READINESS GATES
prod1-74f6d8685b-q4xlj    1/1     Running   0          2m16s   100.96.1.10   ip-172-20-45-19.ap-south-1.compute.internal    <none>           <none>
prod1-74f6d8685b-v6xx2    1/1     Running   0          2m16s   100.96.1.11   ip-172-20-45-19.ap-south-1.compute.internal    <none>           <none>
prod11-57c4d67d7d-9h5xg   1/1     Running   0          15s     100.96.4.8    ip-172-20-50-107.ap-south-1.compute.internal   <none>           <none>
prod11-57c4d67d7d-vns7m   1/1     Running   0          15s     100.96.4.9    ip-172-20-50-107.ap-south-1.compute.internal   <none>           <none>


lets do remove node selcttor and check



apiVersion: apps/v1
kind: Deployment
metadata:
  name: test
  labels:
    app: nginx
spec:
  replicas: 2
  selector:
    matchLabels:
      app: nginx
  template:
    metadata:
      labels:
        app: nginx
    spec:
      containers:
      - name: nginx
        image: nginx:1.14.2
        ports:
        - containerPort: 80
      tolerations:
         - key: "diskType"
           operator: "Equal"
           value: "hdd"
           effect: "NoSchedule"


root@ip-172-31-8-33:~# kubectl get pods -o wide
NAME                      READY   STATUS    RESTARTS   AGE    IP            NODE                                           NOMINATED NODE   READINESS GATES
prod1-74f6d8685b-q4xlj    1/1     Running   0          5m4s   100.96.1.10   ip-172-20-45-19.ap-south-1.compute.internal    <none>           <none>
prod1-74f6d8685b-v6xx2    1/1     Running   0          5m4s   100.96.1.11   ip-172-20-45-19.ap-south-1.compute.internal    <none>           <none>
prod11-57c4d67d7d-9h5xg   1/1     Running   0          3m3s   100.96.4.8    ip-172-20-50-107.ap-south-1.compute.internal   <none>           <none>
prod11-57c4d67d7d-vns7m   1/1     Running   0          3m3s   100.96.4.9    ip-172-20-50-107.ap-south-1.compute.internal   <none>           <none>
test-7b8fd87bb9-cxc8t     1/1     Running   0          16s    100.96.2.3    ip-172-20-95-210.ap-south-1.compute.internal   <none>           <none>
test-7b8fd87bb9-f85gf     1/1     Running   0          16s    100.96.4.10   ip-172-20-50-107.ap-south-1.compute.internal   <none>           <none>


check taint points

check video stop 51:22


apiVersion: apps/v1
kind: Deployment
metadata:
  name: prod1
  labels:
    app: nginx
spec:
  replicas: 2
  selector:
    matchLabels:
      app: nginx
  template:
    metadata:
      labels:
        app: nginx
    spec:
      affinity:
        nodeAffinity:
          requiredDuringSchedulingIgnoredDuringExecution:
            nodeSelectorTerms:
            - matchExpressions:
              - key: env
                operator: In
                values:
                - dev
      containers:
      - name: nginx
        image: nginx:1.14.2
        ports:
        - containerPort: 80
      nodeSelector:
        env: prod
      tolerations:
         - key: "diskType"
           operator: "Equal"
           value: "ssd"
           effect: "NoSchedule"

it when to dev env

1. Single cluster with 10 prod and 10 Dev Nodes.
2. Prod Nodes Labeled as ENV=PRD , dev as ENV=PROD.



kubectl label node ip-172-20-40-248.ap-south-1.compute.internal env=prod --overwrite   
kubectl label node ip-172-20-62-23.ap-south-1.compute.internal env=prod --overwrite
kubectl label node ip-172-20-93-44.ap-south-1.compute.internal  env=dev --overwrite
kubectl label node ip-172-20-95-72.ap-south-1.compute.internal  env=dev --overwrite






apiVersion: apps/v1
kind: Deployment
metadata:
  name: prod1
  labels:
    app: nginx
spec:
  replicas: 4
  selector:
    matchLabels:
      app: nginx
  template:
    metadata:
      labels:
        app: nginx
    spec:
      containers:
      - name: nginx
        image: nginx:1.14.2
        ports:
        - containerPort: 80
it spread pods all nodes so we use to below commands to resict labels for developers

kubectl taint node ip-172-20-40-248.ap-south-1.compute.internal env=prod:NoExecute   
kubectl taint node ip-172-20-62-23.ap-south-1.compute.internal env=prod:NoExecute
kubectl taint node ip-172-20-93-44.ap-south-1.compute.internal  env=dev:NoExecute
kubectl taint node ip-172-20-95-72.ap-south-1.compute.internal  env=dev:NoExecute


prod1-66b6c48dd5-fv6l6   0/1     Pending   0          7s
prod1-66b6c48dd5-tb2td   0/1     Pending   0          7s
prod1-66b6c48dd5-wdtpw   0/1     Pending   0          7s
prod1-66b6c48dd5-xfh4t   0/1     Pending   0          7s




apiVersion: apps/v1
kind: Deployment
metadata:
  name: prod1
  labels:
    app: nginx
spec:
  replicas: 2
  selector:
    matchLabels:
      app: nginx
  template:
    metadata:
      labels:
        app: nginx
    spec:
      containers:
      - name: nginx
        image: nginx:1.14.2
        ports:
        - containerPort: 80
      nodeSelector:
        env: prod
      tolerations:
         - key: "diskType"
           operator: "Equal"
           value: "ssd"
           effect: "NoSchedule"


Events:
  Type     Reason            Age                From               Message
  ----     ------            ----               ----               -------
  Warning  FailedScheduling  29s (x2 over 29s)  default-scheduler  0/5 nodes are available: 1 node(s) had taint {node-role.kubernetes.io/master: }, that the pod didn't tolerate, 2 node(s) had taint {env: dev}, that the pod didn't tolerate, 2 node(s) had taint {env: prod}, that the pod didn't tolerate.
root@ip-172-31-8-33:~# ^C
root@ip-172-31-8-33:~# kubectl get pods
NAME                     READY   STATUS    RESTARTS   AGE
prod1-74f6d8685b-5scfw   0/1     Pending   0          37s
prod1-74f6d8685b-ww7bt   0/1     Pending   0          37s



apiVersion: apps/v1
kind: Deployment
metadata:
  name: prod1
  labels:
    app: nginx
spec:
  replicas: 2
  selector:
    matchLabels:
      app: nginx
  template:
    metadata:
      labels:
        app: nginx
    spec:
      containers:
      - name: nginx
        image: nginx:1.14.2
        ports:
        - containerPort: 80
      nodeSelector:
        env: prod
      tolerations:
         - key: "env"
           operator: "Equal"
           value: "prod"
           effect: "NoExecute"







NAME                     READY   STATUS    RESTARTS   AGE   IP           NODE                                           NOMINATED NODE   READINESS GATES
prod1-7dc9c54dfc-g8lb6   1/1     Running   0          19s   100.96.1.6   ip-172-20-40-248.ap-south-1.compute.internal   <none>           <none>
prod1-7dc9c54dfc-wnwnc   1/1     Running   0          19s   100.96.3.2   ip-172-20-62-23.ap-south-1.compute.internal    <none>           <none>



kubectl taint node ip-172-20-40-248.ap-south-1.compute.internal env=prod:NoExecute   
kubectl taint node ip-172-20-62-23.ap-south-1.compute.internal env=prod:NoExecute
kubectl taint node ip-172-20-93-44.ap-south-1.compute.internal  env=dev:NoExecute
kubectl taint node ip-172-20-95-72.ap-south-1.compute.internal  env=dev:NoExecute



kubectl taint node ip-172-20-40-248.ap-south-1.compute.internal env=prod:NoExecute   
kubectl taint node ip-172-20-62-23.ap-south-1.compute.internal env=prod:NoExecute
kubectl taint node ip-172-20-93-44.ap-south-1.compute.internal  env-
kubectl taint node ip-172-20-95-72.ap-south-1.compute.internal  env-



root@ip-172-31-8-33:~# kubectl taint node ip-172-20-93-44.ap-south-1.compute.internal  env-
node/ip-172-20-93-44.ap-south-1.compute.internal untainted
root@ip-172-31-8-33:~# kubectl taint node ip-172-20-95-72.ap-south-1.compute.internal  env-
node/ip-172-20-95-72.ap-south-1.compute.internal untainted
root@ip-172-31-8-33:~# kubectl taint node ip-172-20-95-72.ap-south-1.compute.internal  env=prod:NoExecute
node/ip-172-20-95-72.ap-south-1.compute.internal tainted
root@ip-172-31-8-33:~# kubectl taint node ip-172-20-93-44.ap-south-1.compute.internal env=prod:NoExecute
node/ip-172-20-93-44.ap-south-1.compute.internal tainted
root@ip-172-31-8-33:~# kubectl node label ip-172-20-95-72.ap-south-1.compute.internal db=yes
Error: unknown command "node" for "kubectl"
Run 'kubectl --help' for usage.
root@ip-172-31-8-33:~# kubectl node label ip-172-20-95-72.ap-south-1.compute.internal env-
Error: unknown command "node" for "kubectl"
Run 'kubectl --help' for usage.
################root@ip-172-31-8-33:~# kubectl label node ip-172-20-95-72.ap-south-1.compute.internal db=yes
#################node/ip-172-20-95-72.ap-south-1.compute.internal labeled                                 {this## commnds use below using--}
#################root@ip-172-31-8-33:~# kubectl label node ip-172-20-93-44.ap-south-1.compute.internaldb=yes
error: resource(s) were provided, but no name was specified
###################root@ip-172-31-8-33:~# kubectl label node ip-172-20-93-44.







NAME                                           STATUS   ROLES                  AGE   VERSION
ip-172-20-34-56.ap-south-1.compute.internal    Ready    control-plane,master   81m   v1.20.11
ip-172-20-40-248.ap-south-1.compute.internal   Ready    node                   80m   v1.20.11
ip-172-20-62-23.ap-south-1.compute.internal    Ready    node                   80m   v1.20.11
ip-172-20-93-44.ap-south-1.compute.internal    Ready    node                   80m   v1.20.11
ip-172-20-95-72.ap-south-1.compute.internal    Ready    node                   80m   v1.20.11
root@ip-172-31-8-33:~# kubectl describe nodes ip-172-20-40-248.ap-south-1.compute.internal | grep -i taint
Taints:             env=prod:NoExecute
root@ip-172-31-8-33:~# kubectl describe nodes ip-172-20-62-23.ap-south-1.compute.internal | grep -i taint
Taints:             env=prod:NoExecute
root@ip-172-31-8-33:~# kubectl describe nodes ip-172-20-93-44.ap-south-1.compute.internal | grep -i taint
Taints:             env=prod:NoExecute
root@ip-172-31-8-33:~# kubectl describe nodes ip-172-20-95-72.ap-south-1.compute.internal | grep -i taint
Taints:             env=prod:NoExecute
root@ip-172-31-8-33:~#









root@ip-172-31-8-33:~# kubectl get nodes --show-labels | grep -i env
ip-172-20-40-248.ap-south-1.compute.internal   Ready    node                   85m   v1.20.11   beta.kubernetes.io/arch=amd64,beta.kubernetes.io/instance-type=t2.medium,beta.kubernetes.io/os=linux,env=prod,failure-domain.beta.kubernetes.io/region=ap-south-1,failure-domain.beta.kubernetes.io/zone=ap-south-1a,kops.k8s.io/instancegroup=nodes-ap-south-1a,kubernetes.io/arch=amd64,kubernetes.io/hostname=ip-172-20-40-248.ap-south-1.compute.internal,kubernetes.io/os=linux,kubernetes.io/role=node,node-role.kubernetes.io/node=,node.kubernetes.io/instance-type=t2.medium,topology.kubernetes.io/region=ap-south-1,topology.kubernetes.io/zone=ap-south-1a
ip-172-20-62-23.ap-south-1.compute.internal    Ready    node                   84m   v1.20.11   beta.kubernetes.io/arch=amd64,beta.kubernetes.io/instance-type=t2.medium,beta.kubernetes.io/os=linux,env=prod,failure-domain.beta.kubernetes.io/region=ap-south-1,failure-domain.beta.kubernetes.io/zone=ap-south-1a,kops.k8s.io/instancegroup=nodes-ap-south-1a,kubernetes.io/arch=amd64,kubernetes.io/hostname=ip-172-20-62-23.ap-south-1.compute.internal,kubernetes.io/os=linux,kubernetes.io/role=node,node-role.kubernetes.io/node=,node.kubernetes.io/instance-type=t2.medium,topology.kubernetes.io/region=ap-south-1,topology.kubernetes.io/zone=ap-south-1a
ip-172-20-93-44.ap-south-1.compute.internal    Ready    node                   84m   v1.20.11   beta.kubernetes.io/arch=amd64,beta.kubernetes.io/instance-type=t2.medium,beta.kubernetes.io/os=linux,db=yes,env=dev,failure-domain.beta.kubernetes.io/region=ap-south-1,failure-domain.beta.kubernetes.io/zone=ap-south-1b,kops.k8s.io/instancegroup=nodes-ap-south-1b,kubernetes.io/arch=amd64,kubernetes.io/hostname=ip-172-20-93-44.ap-south-1.compute.internal,kubernetes.io/os=linux,kubernetes.io/role=node,node-role.kubernetes.io/node=,node.kubernetes.io/instance-type=t2.medium,topology.kubernetes.io/region=ap-south-1,topology.kubernetes.io/zone=ap-south-1b
ip-172-20-95-72.ap-south-1.compute.internal    Ready    node                   84m   v1.20.11   beta.kubernetes.io/arch=amd64,beta.kubernetes.io/instance-type=t2.medium,beta.kubernetes.io/os=linux,db=yes,env=dev,failure-domain.beta.kubernetes.io/region=ap-south-1,failure-domain.beta.kubernetes.io/zone=ap-south-1b,kops.k8s.io/instancegroup=nodes-ap-south-1b,kubernetes.io/arch=amd64,kubernetes.io/hostname=ip-172-20-95-72.ap-south-1.compute.internal,kubernetes.io/os=linux,kubernetes.io/role=node,node-role.kubernetes.io/node=,node.kubernetes.io/instance-type=t2.medium,topology.kubernetes.io/region=ap-south-1,topology.kubernetes.io/zone=ap-south-1b
root@ip-172-31-8-33:~#


root@ip-172-31-8-33:~# kubectl label node ip-172-20-93-44.ap-south-1.compute.internal env-
node/ip-172-20-93-44.ap-south-1.compute.internal labeled
root@ip-172-31-8-33:~# kubectl label node ip-172-20-95-72.ap-south-1.compute.internal env-
node/ip-172-20-95-72.ap-south-1.compute.internal labeled

root@ip-172-31-8-33:~# kubectl get nodes --show-labels | grep -i env
ip-172-20-40-248.ap-south-1.compute.internal   Ready    node                   86m   v1.20.11   beta.kubernetes.io/arch=amd64,beta.kubernetes.io/instance-type=t2.medium,beta.kubernetes.io/os=linux,env=prod,failure-domain.beta.kubernetes.io/region=ap-south-1,failure-domain.beta.kubernetes.io/zone=ap-south-1a,kops.k8s.io/instancegroup=nodes-ap-south-1a,kubernetes.io/arch=amd64,kubernetes.io/hostname=ip-172-20-40-248.ap-south-1.compute.internal,kubernetes.io/os=linux,kubernetes.io/role=node,node-role.kubernetes.io/node=,node.kubernetes.io/instance-type=t2.medium,topology.kubernetes.io/region=ap-south-1,topology.kubernetes.io/zone=ap-south-1a
ip-172-20-62-23.ap-south-1.compute.internal    Ready    node                   86m   v1.20.11   beta.kubernetes.io/arch=amd64,beta.kubernetes.io/instance-type=t2.medium,beta.kubernetes.io/os=linux,env=prod,failure-domain.beta.kubernetes.io/region=ap-south-1,failure-domain.beta.kubernetes.io/zone=ap-south-1a,kops.k8s.io/instancegroup=nodes-ap-south-1a,kubernetes.io/arch=amd64,kubernetes.io/hostname=ip-172-20-62-23.ap-south-1.compute.internal,kubernetes.io/os=linux,kubernetes.io/role=node,node-role.kubernetes.io/node=,node.kubernetes.io/instance-type=t2.medium,topology.kubernetes.io/region=ap-south-1,topology.kubernetes.io/zone=ap-south-1a


root@ip-172-31-8-33:~# kubectl label node ip-172-20-93-44.ap-south-1.compute.internal env=prod
node/ip-172-20-93-44.ap-south-1.compute.internal labeled
root@ip-172-31-8-33:~# kubectl label node ip-172-20-95-72.ap-south-1.compute.internal env=prod
node/ip-172-20-95-72.ap-south-1.compute.internal labeled


apiVersion: apps/v1
kind: Deployment
metadata:
  name: prod2
  labels:
    app: nginx
spec:
  replicas: 4
  selector:
    matchLabels:
      app: nginx
  template:
    metadata:
      labels:
        app: nginx
    spec:
      containers:
      - name: nginx
        image: nginx:1.14.2
        ports:
        - containerPort: 80
      nodeSelector:
        env: prod
      tolerations:
         - key: "env"
           operator: "Equal"
           value: "prod"
           effect: "NoExecute"

root@ip-172-31-8-33:~# kubectl get pods -o wide
NAME                     READY   STATUS    RESTARTS   AGE   IP           NODE                                           NOMINATED NODE   READINESS GATES
prod2-7dc9c54dfc-64lrk   1/1     Running   0          10s   100.96.4.8   ip-172-20-95-72.ap-south-1.compute.internal    <none>           <none>
prod2-7dc9c54dfc-dtwwg   1/1     Running   0          10s   100.96.1.7   ip-172-20-40-248.ap-south-1.compute.internal   <none>           <none>
prod2-7dc9c54dfc-ghm5t   1/1     Running   0          10s   100.96.3.3   ip-172-20-62-23.ap-south-1.compute.internal    <none>           <none>
prod2-7dc9c54dfc-qh5wv   1/1     Running   0          10s   100.96.2.7   ip-172-20-93-44.ap-south-1.compute.internal    <none>           <none>



--kubectl label node ip-172-20-95-72.ap-south-1.compute.internal db=yes
--kubectl label node ip-172-20-93-44.ap-south-1.compute.internaldb=yes


kubectl label node ip-172-20-95-72.ap-south-1.compute.internal db=mysql --overwrite
kubectl label node ip-172-20-93-44.ap-south-1.compute.internal db=mysql --overwrite

apiVersion: apps/v1
kind: Deployment
metadata:
  name: prod1
  labels:
    app: nginx
spec:
  replicas: 4
  selector:
    matchLabels:
      app: nginx
  template:
    metadata:
      labels:
        app: nginx
    spec:
      containers:
      - name: nginx
        image: nginx:1.14.2
        ports:
        - containerPort: 80
      nodeSelector:
        db: 'mysql'
      tolerations:
         - key: "env"
           operator: "Equal"
           value: "prod"
           effect: "NoExecute"


prod1-76d455ffbf-5f69w   1/1     Running   0          11s   100.96.2.10   ip-172-20-93-44.ap-south-1.compute.internal   <none>           <none>
prod1-76d455ffbf-78v7x   1/1     Running   0          11s   100.96.2.11   ip-172-20-93-44.ap-south-1.compute.internal   <none>           <none>
prod1-76d455ffbf-qxt4j   1/1     Running   0          11s   100.96.4.12   ip-172-20-95-72.ap-south-1.compute.internal   <none>           <none>
prod1-76d455ffbf-snlh9   1/1     Running   0          11s   100.96.4.11   ip-172-20-95-72.ap-south-1.compute.internal   <none>           <none>



apiVersion: apps/v1
kind: Deployment
metadata:
  name: prod1
  labels:
    app: nginx
spec:
  replicas: 4
  selector:
    matchLabels:
      app: nginx
  template:
    metadata:
      labels:
        app: nginx
    spec:
      affinity:
        nodeAffinity:
          requiredDuringSchedulingIgnoredDuringExecution:
            nodeSelectorTerms:
            - matchExpressions:
              - key: db
                operator: In
                values:
                - mysql
      containers:
      - name: nginx
        image: nginx:1.14.2
        ports:
        - containerPort: 80
      tolerations:
         - key: "env"
           operator: "Equal"
           value: "prod"
           effect: "NoExecute"


root@ip-172-31-8-33:~# kubectl get pods -o wide
NAME                     READY   STATUS    RESTARTS   AGE   IP            NODE                                          NOMINATED NODE   READINESS GATES
prod1-57bd4c89f7-4nklj   1/1     Running   0          6s    100.96.2.12   ip-172-20-93-44.ap-south-1.compute.internal   <none>           <none>
prod1-57bd4c89f7-58qjb   1/1     Running   0          6s    100.96.4.14   ip-172-20-95-72.ap-south-1.compute.internal   <none>           <none>
prod1-57bd4c89f7-tblc5   1/1     Running   0          6s    100.96.2.13   ip-172-20-93-44.ap-south-1.compute.internal   <none>           <none>
prod1-57bd4c89f7-xb4md   1/1     Running   0          6s    100.96.4.13   ip-172-20-95-72.ap-south-1.compute.internal   <none>           <none>
