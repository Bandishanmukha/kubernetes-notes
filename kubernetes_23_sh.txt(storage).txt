kubernetes-Storage

No Data Is Saved

Stateless & Statefull

Volumes
emptydir:- if pod deleted this emptydir will also deleted
HostPath:-


apiVersion: v1
kind: Pod
metadata:
  name: mypod
spec:
  containers:
  - name: mypod1
    image: sreeharshav/rollingupdate:v1
    volumeMounts:
      - name: testvol
        mountPath: /tmp/testvolume
  volumes:
     - name: testvol
       emptyDir: {}


root@ip-172-31-40-54:~# echo 'apiVersion: v1
> kind: Pod
> metadata:
>   name: mypod
> spec:
>   containers:
>   - name: mypod1
>     image: sreeharshav/rollingupdate:v1
>     volumeMounts:
>       - name: testvol
>         mountPath: /tmp/testvolume
>   volumes:
>      - name: testvol
>        emptyDir: {}' | kubectl create -f -
pod/mypod created



apiVersion: v1
kind: Pod
metadata:
  name: mypod
spec:
  containers:
  - name: mypod1
    image: sreeharshav/rollingupdate:v1
    volumeMounts:
      - name: testvol
        mountPath: /tmp/testvolume
  - name: mypod2
    image: busybox:latest
    command: ["sleep"] 
    args: ["3600"]
    volumeMounts:
      - name: testvol
        mountPath: /tmp/testvolume      
  volumes:
     - name: testvol
       emptyDir: {}


root@ip-172-31-40-54:~# echo 'apiVersion: v1
> kind: Pod
> metadata:
>   name: mypod
> spec:
>   containers:
>   - name: mypod1
>     image: sreeharshav/rollingupdate:v1
>     volumeMounts:
>       - name: testvol
>         mountPath: /tmp/testvolume
>   - name: mypod2
>     image: busybox:latest
>     command: ["sleep"]
>     args: ["3600"]
>     volumeMounts:
>       - name: testvol
  volumes:
     - name: testvol
       emptyDir: {}>         mountPath: /tmp/testvolume
>   volumes:
>      - name: testvol
>        emptyDir: {}' | kubectl create -f -
pod/mypod created







root@ip-172-31-40-54:~# kubectl get pods
NAME    READY   STATUS    RESTARTS   AGE
mypod   1/1     Running   0          19s
root@ip-172-31-40-54:~#


root@ip-172-31-40-54:~# kubectl exec -it mypod -- ls /tmp/testvolume



root@ip-172-31-40-54:~# kubectl exec -it mypod -- ls /tmp/testvolume
root@ip-172-31-40-54:~# ^C
root@ip-172-31-40-54:~# kubectl exec -it mypod -- touch /tmp/testvolume/file1
root@ip-172-31-40-54:~# kubectl exec -it mypod -- touch /tmp/testvolume/file2
root@ip-172-31-40-54:~# kubectl exec -it mypod -- touch /tmp/testvolume/file3
root@ip-172-31-40-54:~# kubectl exec -it mypod -- ls /tmp/testvolume
file1  file2  file3


root@ip-172-31-40-54:~# kubectl delete pod mypod
pod "mypod" deleted


files are deleted




root@ip-172-31-40-54:~# kubectl exec -i│root@ip-172-31-40-54:~#               │root@ip-172-31-40-54:~#                │root@ip-172-31-40-54:~#
t mypod -c mypod1 -- bash    


apt update && apt install│root@ip-172-31-40-54:~#               │root@ip-172-31-40-54:~#                │root@ip-172-31-40-54:~#
 -y watch     

root@mypod:/# watch -n 1 ls /tmp/testvo│                                      │                                       │
lume                   

root@mypod:/# watch -n 1 /tmp/testvolum│root@ip-172-31-40-54:~# ls /tmp/      │root@ip-172-31-40-54:~#                │root@ip-172-31-40-54:~#
e                                      │snap.lxd                              │                                       │
root@mypod:/# watch -n 1 ls /tmp/testvo│systemd-private-34988071fabb4290a87ee8│                                       │
lume                                   │21c3fc249b-fwupd.service-occitj       │                                       │
root@mypod:/# watch -n 1 ls /tmp/testvo│systemd-private-34988071fabb4290a87ee8│                                       │
lume ^C                                │21c3fc249b-systemd-logind.service-ALYn│                                       │
root@mypod:/#                          │Uf                                    │                                       │
                                       │systemd-private-34988071fabb4290a87ee8│                                       │
                                       │21c3fc249b-systemd-resolved.service-wd│                                       │
                                       │wXxf                                  │                                       │
                                       │systemd-private-34988071fabb4290a87ee8│                                       │
                                       │21c3fc249b-systemd-timesyncd.service-H│                                       │
                                       │J0Onj                                 │                                       │
                                       │tmux-0                                │                                       │
                                       │root@ip-172-31-40-54:~# kubectl exec -│                                       │
                                       │it mypod -c  mypod2  -- sh            │                                       │
                                       │/ #                                   │                                       │
                                       │                                      │    




root@ip-172-31-40-54:~# tmux
        mypod: Wed Sep 29 15:55:42 2021│/tmp/testvolume # I=0                 │root@ip-172-31-40-54root@ip-172-31-40-5│root@ip-172-31-40-5root@ip-172-31-40-5
                                       │/tmp/testvolume # while ( $I -lt 100) │root@ip-172-31-40-54:~#                │root@ip-172-31-40-54:~#
file0                                  │> do                                  │                                       │
file1                                  │> echo $(data) > file$I               │                                       │
file10                                 │> sleep 2                             │                                       │
file11                                 │> I=$(( $I + l ))                     │                                       │
file12                                 │> done                                │                                       │
file13                                 │sh: 0: not found                      │                                       │
file14                                 │/tmp/testvolume # I=0                 │                                       │
file15                                 │/tmp/testvolume #  while ( $I -lt 100)│                                       │
file16                                 │> do                                  │                                       │
file17                                 │> echo $(data) > file$I               │                                       │
file18                                 │> sleep 2                             │                                       │
file19                                 │> I=$(( $I + 1 ))                     │                                       │
file2                                  │> done                                │                                       │
file20                                 │sh: 0: not found                      │                                       │
file21                                 │/tmp/testvolume #                     │                                       │
file22                                 │                                      │        


                   NODE 
                   pod
GitHUB---------->>>NGINX=====================>>SVC



apiVersion: v1
kind: Pod
metadata:
  name: mypod1
spec:
  containers:
  - name: mypod1
    image: nginx:latest


root@ip-172-31-40-54:~# echo 'apiVersion: v1
kind: Pod
metadata:
  name: mypod1
spec:
  containers:
  - name: mypod1
    image: nginx:latest' | kubectl create -f -
pod/mypod1 created



root@ip-172-31-40-54:~# kubectl get pods
NAME     READY   STATUS    RESTARTS   AGE
mypod    2/2     Running   0          30m
mypod1   1/1     Running   0          39s


root@ip-172-31-40-54:~# kubectl get pods --show-labels
NAME     READY   STATUS    RESTARTS   AGE   LABELS
mypod    2/2     Running   0          31m   <none>
mypod1   1/1     Running   0          78s   <none>


root@ip-172-31-40-54:~# kubectl label pod mypod1 name=nginx
pod/mypod1 labeled


root@ip-172-31-40-54:~# kubectl expose pod mypod1 --port=8000 --target-port=80 --type=NodePort
service/mypod1 exposed
root@ip-172-31-40-54:~# kubectl get svc
NAME         TYPE        CLUSTER-IP       EXTERNAL-IP   PORT(S)          AGE
kubernetes   ClusterIP   100.64.0.1       <none>        443/TCP          124m
mypod1       NodePort    100.70.225.246   <none>        8000:30992/TCP   7s
root@ip-172-31-40-54:~#


apiVersion: v1
kind: Pod
metadata:
  name: mypod1
spec:
  containers:
  - name: mypod1
    image: nginx:latest
    volumeMounts:
      - name: testvol
        mountPath: /usr/share/nginx/html
  volumes:
     - name: testvol
       gitRepo:
         repository: https://github.com/mavrick202/dockertest1.git
         revision: k8sb1


root@ip-172-31-40-54:~# echo 'apiVersion: v1
> kind: Pod
> metadata:
>   name: mypod1
> spec:
>   containers:
>   - name: mypod1
>     image: nginx:latest
>     volumeMounts:
>       - name: testvol
>         mountPath: /usr/share/nginx/html
>   volumes:
>      - name: testvol
>        gitRepo:
>          repository: https://github.com/mavrick202/dockertest1.git
>          revision: k8sb1' | kubectl create -f -
pod/mypod1 created
root@ip-172-31-40-54:~#


root@ip-172-31-40-54:~# kubectl get pods
NAME     READY   STATUS              RESTARTS   AGE
mypod    2/2     Running             0          40m
mypod1   0/1     ContainerCreating   0          105s
root@ip-172-31-40-54:~# kubectl exec -it mypod -- bash
Defaulted container "mypod1" out of: mypod1, mypod2
root@mypod:/# ls /usr/share/nginx/html/
50x.html  index.html  scorekeeper.js  style.css



apiVersion: v1
kind: Pod
metadata:
  name: mypod1
spec:
  containers:
  - name: mypod1
    image: nginx:latest
    volumeMounts:
      - name: testvol
        mountPath: /usr/share/nginx/html
  volumes:
     - name: testvol
       gitRepo:
         repository: https://github.com/mavrick202/dockertest1.git
         revision: k8sb1
         directory: .


root@ip-172-31-40-54:~# echo 'apiVersion: v1
kind: Pod
metadata:
  name: mypod1
spec:
  containers:
  - name: mypod1
    image: nginx:latest
    volumeMounts:
      - name: testvol
        mountPath: /usr/share/nginx/html
  volumes:
     - name: testvol
       gitRepo:
         repository: https://github.com/mavrick202/dockertest1.git
         revision: k8sb1
         directory: .' | kubectl create -f -
pod/mypod1 created
root@ip-172-31-40-54:~# kubectl get pods
NAME     READY   STATUS              RESTARTS   AGE
mypod    2/2     Running             0          44m
mypod1   0/1     ContainerCreating   0          5s
root@ip-172-31-40-54:~#


* this sceniro it clone the git apply changes but doesnt do pull



how we use side car


                   NODE 
                   pod
GitHUB------------------------------------------------------------->>>NGINX========================================================================>>SVC
  |  |______________________________> emptydir(it did only git pull)-->|
  |<_______________________________-git-sync/side-car(get initmated from git repo having any changes)           

why we use in multiple container in one pod

we use for git synnk from my emptydir



apiVersion: v1
kind: Pod
metadata:
  name: gitrepo-volume-pod
  labels:
    name: gitrepo-volume-pod
spec:
  containers:
  - image: sreeharshav/rollingupdate:v3
    name: web-server
    ports:
      - containerPort: 80
        protocol: TCP
    volumeMounts:
    - name: html
      mountPath: /usr/share/nginx/

  - name: git-sync
    image: k8s.gcr.io/git-sync:v3.0.1
    volumeMounts:
        - name: html
          mountPath: /tmp/git/
    env:
        - name: GIT_SYNC_REPO
          value: https://github.com/mavrick202/dockertest1.git
        - name: GIT_SYNC_BRANCH
          value: feature3
        - name: GIT_SYNC_DEST
          value: html
  volumes:
   - name: html
     emptyDir: {}


apiVersion: v1
kind: Pod
metadata:
  name: gitrepo-volume-pod
  labels:
    name: nginx
spec:
  containers:
  - image: sreeharshav/rollingupdate:v3
    name: web-server
    ports:
      - containerPort: 80
        protocol: TCP
    volumeMounts:
    - name: html
      mountPath: /usr/share/nginx/

  - name: git-sync
    image: k8s.gcr.io/git-sync:v3.0.1
    volumeMounts:
        - name: html
          mountPath: /tmp/git/
    env:
        - name: GIT_SYNC_REPO
          value: https://github.com/mavrick202/dockertest1.git
        - name: GIT_SYNC_BRANCH
          value: feature3
        - name: GIT_SYNC_DEST
          value: html
  volumes:
   - name: html
     emptyDir: {}


root@ip-172-31-40-54:~# echo 'apiVersion: v1
> kind: Pod
> metadata:
>   name: gitrepo-volume-pod
>   labels:
>     name: nginx
> spec:
    name: web-server
    ports:
      - containerPort: 80
        protocol: TCP
    volumeMounts:
>   containers:
>   - image: sreeharshav/rollingupdate:v3
>     name: web-server
>     ports:
>       - containerPort: 80
>         protocol: TCP
>     volumeMounts:
>     - name: html
>       mountPath: /usr/share/nginx/
>
>   - name: git-sync
>     image: k8s.gcr.io/git-sync:v3.0.1
>     volumeMounts:
>         - name: html
>           mountPath: /tmp/git/
>     env:
>         - name: GIT_SYNC_REPO
>           value: https://github.com/mavrick202/dockertest1.git
>         - name: GIT_SYNC_BRANCH
>           value: feature3
>         - name: GIT_SYNC_DEST
>           value: html
>   volumes:
>    - name: html
>      emptyDir: {}
> ' | kubectl create -f -
pod/gitrepo-volume-pod created
root@ip-172-31-40-54:~#


same scennrio we use if user upload in pdf in svc through ndinx nginx to empty dir empty-dir to git-synx  git-synx to git repo

use empty dir for share data for all container

if we lost pod data will doesnt lost  use pressitent volume
uselike ebs, NFS etc



-----------------------------------------------------
ebs mount to pod
Create volume add tags
EBS Tags => KubernetesCluster: kiwidev.xyz

apiVersion: v1
kind: Pod
metadata:
  name: test-ebs
  labels: 
     name: raw-volume-testing
spec:
  containers:
  - image: nginx:latest
    name: test-container
    volumeMounts:
    - mountPath: /usr/share/nginx/html/
      name: test-volume
  volumes:
  - name: test-volume
    # This AWS EBS volume must already exist.
    awsElasticBlockStore:
      volumeID: vol-0c9f69c2197106e12
      fsType: ext4


root@ip-172-31-40-54:~# echo 'apiVersion: v1
> kind: Pod
> metadata:
>   name: test-ebs
>   labels:
>      name: raw-volume-testing
> spec:
>   containers:
>   - image: nginx:latest
>     name: test-container
>     volumeMounts:
>     - mountPath: /usr/share/nginx/html/
>       name: test-volume
>   volumes:
>   - name: test-volume
>     # This AWS EBS volume must already exist.
>     awsElasticBlockStore:
>       volumeID: vol-0c9f69c2197106e12
>       fsType: ext4
>
> ' | kubectl create -f -
pod/test-ebs created


root@ip-172-31-40-54:~# kubectl logs test-ebs
/docker-entrypoint.sh: /docker-entrypoint.d/ is not empty, will attempt to perform configuration
/docker-entrypoint.sh: Looking for shell scripts in /docker-entrypoint.d/
/docker-entrypoint.sh: Launching /docker-entrypoint.d/10-listen-on-ipv6-by-default.sh
10-listen-on-ipv6-by-default.sh: info: Getting the checksum of /etc/nginx/conf.d/default.conf
10-listen-on-ipv6-by-default.sh: info: Enabled listen on IPv6 in /etc/nginx/conf.d/default.conf
/docker-entrypoint.sh: Launching /docker-entrypoint.d/20-envsubst-on-templates.sh
/docker-entrypoint.sh: Launching /docker-entrypoint.d/30-tune-worker-processes.sh
/docker-entrypoint.sh: Configuration complete; ready for start up
2021/09/29 17:16:26 [notice] 1#1: using the "epoll" event method
2021/09/29 17:16:26 [notice] 1#1: nginx/1.21.3
2021/09/29 17:16:26 [notice] 1#1: built by gcc 8.3.0 (Debian 8.3.0-6)
2021/09/29 17:16:26 [notice] 1#1: OS: Linux 5.11.0-1017-aws
2021/09/29 17:16:26 [notice] 1#1: getrlimit(RLIMIT_NOFILE): 1048576:1048576
2021/09/29 17:16:26 [notice] 1#1: start worker processes
2021/09/29 17:16:26 [notice] 1#1: start worker process 30
2021/09/29 17:16:26 [notice] 1#1: start worker process 31
root@ip-172-31-40-54:~#
root@ip-172-31-40-54:~# kubectl logs test-ebs
/docker-entrypoint.sh: /docker-entrypoint.d/ is not empty, will attempt to perform configuration
/docker-entrypoint.sh: Looking for shell scripts in /docker-entrypoint.d/
/docker-entrypoint.sh: Launching /docker-entrypoint.d/10-listen-on-ipv6-by-default.sh
10-listen-on-ipv6-by-default.sh: info: Getting the checksum of /etc/nginx/conf.d/default.conf
10-listen-on-ipv6-by-default.sh: info: Enabled listen on IPv6 in /etc/nginx/conf.d/default.conf
/docker-entrypoint.sh: Launching /docker-entrypoint.d/20-envsubst-on-templates.sh
/docker-entrypoint.sh: Launching /docker-entrypoint.d/30-tune-worker-processes.sh
/docker-entrypoint.sh: Configuration complete; ready for start up
2021/09/29 17:16:26 [notice] 1#1: using the "epoll" event method
2021/09/29 17:16:26 [notice] 1#1: nginx/1.21.3
2021/09/29 17:16:26 [notice] 1#1: built by gcc 8.3.0 (Debian 8.3.0-6)
2021/09/29 17:16:26 [notice] 1#1: OS: Linux 5.11.0-1017-aws
2021/09/29 17:16:26 [notice] 1#1: getrlimit(RLIMIT_NOFILE): 1048576:1048576
2021/09/29 17:16:26 [notice] 1#1: start worker processes
2021/09/29 17:16:26 [notice] 1#1: start worker process 30
2021/09/29 17:16:26 [notice] 1#1: start worker process 31
root@ip-172-31-40-54:~# ^C
root@ip-172-31-40-54:~# kubectl exec -it test-ebs -- bash
root@test-ebs:/# ls /usr/share/nginx/html/
lost+found
root@test-ebs:/# apt update && apt install git install
Get:1 http://deb.debian.org/debian buster InRelease [122 kB]
Get:2 http://deb.debian.org/debian buster-updates InRelease [51.9 kB]
Get:3 http://security.debian.org/debian-security buster/updates InRelease [65.4 kB]
Get:4 http://deb.debian.org/debian buster/main amd64 Packages [7907 kB]
Get:5 http://deb.debian.org/debian buster-updates/main amd64 Packages [15.2 kB]
Get:6 http://security.debian.org/debian-security buster/updates/main amd64 Packages [305 kB]
Fetched 8466 kB in 2s (5363 kB/s)
Reading package lists... Done
Building dependency tree
Reading state information... Done
1 package can be upgraded. Run 'apt list --upgradable' to see it.
Reading package lists... Done
Building dependency tree
Reading state information... Done
E: Unable to locate package install
root@test-ebs:/#
inside pod
git clone repo

cp dockertest1/* /user/share/nginx/html
hit the google

change label to nginx
kubect edit svc pod name

stop 1:05

3 types to assign volumes
1, direct access   ====> Mount directly raw volume to assign in pod it was doent suggested
2. static ====> pv and pvc
3. dynamic


2. EBS-1(500GB)        EBS-1(500GB)                     EBS-1(500GB)
    10gbPV1 10gbPV2 10gbPV3 10gbPV4 10gbPV5 10gbPV6 10gbPV7 10gbPV8
     |
 PVC- 5gb
  POD  



apiVersion: apps/v1
kind: Deployment
metadata:
  name: nginx-deployment
  labels:
    app: mongodb
spec:
  replicas: 1
  selector:
    matchLabels:
      app: mongodb
      name: mongodb
  template:
    metadata:
      labels:
        app: mongodb
        name: mongodb
    spec:
      containers:
      - image: mongo
        name: mongodb
        imagePullPolicy: Always
        volumeMounts:
        - name: mongodb-data
          mountPath: /data/db
      volumes:
      - name: mongodb-data
        awsElasticBlockStore:
           volumeID: vol-0cfc58a58832bc418
           fsType: ext4


EBS is a persistent block storage with a defined size (It is however possible to change it later). 
It is fully configurable and could be the most performant solution of Amazon. 
The major drawback is that it can be only mounted to one EC2 instance. 
This also means that it can't be shared between multiple pods.
https://kubernetes.io/docs/concepts/storage/persistent-volumes/
https://blog.abyssale.com/shared-storage-volume-on-amazon/

PV & PVC:

●	RWO - ReadWriteOnce
●	ROX - ReadOnlyMany
●	RWX - ReadWriteMany
The access modes are:
●	ReadWriteOnce -- the volume can be mounted as read-write by a single node
●	ReadOnlyMany -- the volume can be mounted read-only by many nodes
●	ReadWriteMany -- the volume can be mounted as read-write by many nodes
A volume will be in one of the following phases:
●	Available -- a free resource that is not yet bound to a claim
●	Bound -- the volume is bound to a claim
●	Released -- the claim has been deleted, but the resource is not yet reclaimed by the cluster
●	Failed -- the volume has failed its automatic reclamation




apiVersion: apps/v1
kind: Deployment
metadata:
  name: nginx-deployment
  labels:
    app: mongodb
spec:
  replicas: 3
  selector:
    matchLabels:
      app: mongodb
      name: mongodb
  template:
    metadata:
      labels:
        app: mongodb
        name: mongodb
    spec:
      containers:
      - image: mongo
        name: mongodb
        imagePullPolicy: Always
        volumeMounts:
        - name: mongodb-data
          mountPath: /data/db
      volumes:
      - name: mongodb-data
        awsElasticBlockStore:
           volumeID: vol-0cfc58a58832bc418
           fsType: ext4

deployed

one one pod will run becasue 1 volume can attached one pod remaning pod dont have vol

