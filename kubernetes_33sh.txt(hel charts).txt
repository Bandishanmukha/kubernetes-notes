Kubernetes Helm --> is an package manager for kubernetes service



Mgmt server                                 worker node                worker node




           
helm chart---------commuicated---------------->Tiller(which version package to deploy)


https://github.com/helm/helm/releases


 wget https://get.helm.sh/helm-v3.7.1-linux-amd64.tar.gz


root@ip-172-31-8-33:~# tar -zxvf helm-v3.7.1-linux-amd64.tar.gz
linux-amd64/
linux-amd64/helm
linux-amd64/LICENSE
linux-amd64/README.md
root@ip-172-31-8-33:~#


root@ip-172-31-8-33:~# ls
FluentD.sh  helm-v3.7.1-linux-amd64.tar.gz  pod.yml  stateful_mysql.yml
efk         linux-amd64                     snap     upgrade.sh
root@ip-172-31-8-33:~# cd linux-amd64/
root@ip-172-31-8-33:~/linux-amd64#


root@ip-172-31-8-33:~/linux-amd64# ls
LICENSE  README.md  helm
root@ip-172-31-8-33:~/linux-amd64#


mv helm /usr/local/bin/

root@ip-172-31-8-33:~/linux-amd64# helm list
NAME    NAMESPACE       REVISION        UPDATED STATUS  CHART   APP VERSION
root@ip-172-31-8-33:~/linux-amd64#


root@ip-172-31-8-33:~/linux-amd64# helm create myfirstchart
Creating myfirstchart

root@ip-172-31-8-33:~/linux-amd64# ls
LICENSE  README.md  myfirstchart


apt install tree -y


root@ip-172-31-8-33:~/linux-amd64# tree
.
├── LICENSE
├── README.md
└── myfirstchart
    ├── Chart.yaml
    ├── charts
    ├── templates
    │   ├── NOTES.txt
    │   ├── _helpers.tpl
    │   ├── deployment.yaml
    │   ├── hpa.yaml
    │   ├── ingress.yaml
    │   ├── service.yaml
    │   ├── serviceaccount.yaml
    │   └── tests
    │       └── test-connection.yaml
    └── values.yaml

4 directories, 12 files
root@ip-172-31-8-33:~/linux-amd64#


root@ip-172-31-8-33:~/linux-amd64# tree myfirstchart/
myfirstchart/
├── Chart.yaml
├── charts
├── templates
│   ├── NOTES.txt
│   ├── _helpers.tpl
│   ├── deployment.yaml
│   ├── hpa.yaml
│   ├── ingress.yaml
│   ├── service.yaml
│   ├── serviceaccount.yaml
│   └── tests
│       └── test-connection.yaml
└── values.yaml

3 directories, 10 files
root@ip-172-31-8-33:~/linux-amd64#



root@ip-172-31-8-33:~/linux-amd64# cd myfirstchart/templates/
root@ip-172-31-8-33:~/linux-amd64/myfirstchart/templates# ls
NOTES.txt     deployment.yaml  ingress.yaml  serviceaccount.yaml
_helpers.tpl  hpa.yaml         service.yaml  tests


root@ip-172-31-8-33:~/linux-amd64/myfirstchart/templates# kubectl create ns testing --dry-run -o yaml
W1018 14:15:16.480258    1455 helpers.go:555] --dry-run is deprecated and can be replaced with --dry-run=client.
apiVersion: v1
kind: Namespace
metadata:
  creationTimestamp: null
  name: testing
spec: {}
status: {}



kubectl run testdeploy --image=sreeharshav/rollingupdate:v4 -n testing --dry-run -o yaml

apiVersion: v1
kind: Pod
metadata:
  creationTimestamp: null
  labels:
    run: testdeploy
  name: testdeploy
  namespace: testing
spec:
  containers:
  - image: sreeharshav/rollingupdate:v4
    name: testdeploy
    resources: {}
  dnsPolicy: ClusterFirst
  restartPolicy: Always
status: {}



above contained delete in deployement.yml

apiVersion: v1
kind: Namespace
metadata:
  name: testing
---
apiVersion: apps/v1
kind: Deployment
metadata:
  name: nginx-deployment
  namespace: testing
  labels:
    app: nginx
spec:
  replicas: 3
  selector:
    matchLabels:
      app: nginx
  template:
    metadata:
      labels:
        app: nginx
    spec:
      containers:
      - name: nginx
        image: sreeharshav/rollingupdate:v4
        ports:
        - containerPort: 80
---
apiVersion: v1
kind: Service
metadata:
  name: my-service
  namespace: testing
spec:
  selector:
    app: nginx
  ports:
    - protocol: TCP
      port: 80
      targetPort: 8000
  type: NodePort


root@ip-172-31-8-33:~/linux-amd64# helm lint myfirstchart/
==> Linting myfirstchart/
[INFO] Chart.yaml: icon is recommended

1 chart(s) linted, 0 chart(s) failed
root@ip-172-31-8-33:~/linux-amd64#


root@ip-172-31-8-33:~/linux-amd64# helm package myfirstchart/
Successfully packaged chart and saved it to: /root/linux-amd64/myfirstchart-0.1.0.tgz


helm install chart-testing /root/linux-amd64/myfirstchart-0.1.0.tgz 


root@ip-172-31-8-33:~/linux-amd64/myfirstchart/templates# helm uninstall chart-testing
release "chart-testing" uninstalled
 

video pending 55:22


root@ip-172-31-8-33:~# helm create storageefs
Creating storageefs



root@ip-172-31-8-33:~# helm create test1
Creating test1


vi test1/templates/deployment.yaml


apiVersion: v1
kind: Namespace
metadata:
  name: testing
---
apiVersion: apps/v1
kind: Deployment
metadata:
  name: nginx-deployment
  namespace: testing
  labels:
    app: nginx
spec:
  replicas: 3
  selector:
    matchLabels:
      app: nginx
  template:
    metadata:
      labels:
        app: nginx
    spec:
      containers:
      - name: nginx
        image: sreeharshav/rollingupdate:v4
        ports:
        - containerPort: 80
---
apiVersion: v1
kind: Service
metadata:
  name: my-service
  namespace: testing
spec:
  selector:
    app: nginx
  ports:
    - protocol: TCP
      port: 80
      targetPort: 8000
  type: NodePort





root@ip-172-31-8-33:~# helm lint test1
==> Linting test1
[INFO] Chart.yaml: icon is recommended

1 chart(s) linted, 0 chart(s) failed
root@ip-172-31-8-33:~# helm package test1
Successfully packaged chart and saved it to: /root/test1-0.1.0.tgz
root@ip-172-31-8-33:~#


 helm install testinstall /root/test1-0.1.0.tgz --dry-run


helm create charttest2
Creating charttest2


 vi charttest2/templates/deployment.yaml


apiVersion: v1
kind: Namespace
metadata:
  name: {{ .Values.nameSpace }}
---
apiVersion: apps/v1
kind: Deployment
metadata:
  name: {{ .Values.deployName }}
  namespace: {{ .Values.nameSpace }}
  labels:
    app: nginx
spec:
  replicas: 3
  selector:
    matchLabels:
      app: nginx
  template:
    metadata:
      labels:
        app: nginx
    spec:
      containers:
      - name: nginx
        image: sreeharshav/rollingupdate:v4
        ports:
        - containerPort: 80
---
apiVersion: v1
kind: Service
metadata:
  name: my-service
  namespace: {{ .Values.nameSpace }}
spec:
  selector:
    app: nginx
  ports:
    - protocol: TCP
      port: 80
      targetPort: 8000
  type: NodePort


root@ip-172-31-8-33:~# helm package charttest2/
Successfully packaged chart and saved it to: /root/charttest2-0.1.0.tgz
root@ip-172-31-8-33:~# helm install testing1 /root/charttest2-0.1.0.tgz --dry-run
Error: INSTALLATION FAILED: rendered manifests contain a resource that already exists. Unable to continue with install: could not get information about the resource: resource name may not be empty
root@ip-172-31-8-33:~#


 helm install testing1 /root/charttest2-0.1.0.tgz --dry-run --set nameSpace=test123 --set deployName=deploy1


 helm install testing1 /root/charttest2-0.1.0.tgz --set nameSpace=test123 --set deployName=deploy1


root@ip-172-31-8-33:~# kubectl get pods -n test123
NAME                       READY   STATUS    RESTARTS   AGE
deploy1-588d974c98-5vtgs   1/1     Running   0          42s
deploy1-588d974c98-bsz9f   1/1     Running   0          42s
deploy1-588d974c98-kd2pk   1/1     Running   0          42s
root@ip-172-31-8-33:~#


root@ip-172-31-8-33:~# helm install testing2 /root/charttest2-0.1.0.tgz --set nameSpace=test1234 --set deployName=deploy2


root@ip-172-31-8-33:~# helm list
NAME            NAMESPACE       REVISION        UPDATED                                 STATUS          CHART                   APP VERSION
testing1        default         1               2021-10-19 10:19:13.438663293 +0000 UTC deployed        charttest2-0.1.0        1.16.0
testing2        default         1               2021-10-19 10:21:21.927773972 +0000 UTC deployed        charttest2-0.1.0        1.16.0
root@ip-172-31-8-33:~#


root@ip-172-31-8-33:~# helm uninstall testing1
release "testing1" uninstalled
root@ip-172-31-8-33:~# helm uninstall testing2
release "testing2" uninstalled


after create EFS


root@ip-172-31-8-33:~# helm create efs
Creating efs
root@ip-172-31-8-33:~# cd ef
efk/ efs/
root@ip-172-31-8-33:~# cd efs/templates/
root@ip-172-31-8-33:~/efs/templates# vi deployment.yaml


apiVersion: v1
kind: Namespace
metadata:
  name: efs-provisioner
  
---
kind: ClusterRole
apiVersion: rbac.authorization.k8s.io/v1
metadata:
  name: efs-provisioner-runner
rules:
  - apiGroups: [""]
    resources: ["persistentvolumes"]
    verbs: ["get", "list", "watch", "create", "delete"]
  - apiGroups: [""]
    resources: ["persistentvolumeclaims"]
    verbs: ["get", "list", "watch", "update"]
  - apiGroups: ["storage.k8s.io"]
    resources: ["storageclasses"]
    verbs: ["get", "list", "watch"]
  - apiGroups: [""]
    resources: ["events"]
    verbs: ["create", "update", "patch"]
  - apiGroups: [""]
    resources: ["endpoints"]
    verbs: ["get", "list", "watch", "create", "update", "patch"]

---
kind: ClusterRoleBinding
apiVersion: rbac.authorization.k8s.io/v1
metadata:
  name: run-efs-provisioner
subjects:
  - kind: ServiceAccount
    name: efs-provisioner
     # replace with namespace where provisioner is deployed
    namespace: efs-provisioner
roleRef:
  kind: ClusterRole
  name: efs-provisioner-runner
  apiGroup: rbac.authorization.k8s.io
  
---
kind: Role
apiVersion: rbac.authorization.k8s.io/v1
metadata:
  name: leader-locking-efs-provisioner
  namespace: efs-provisioner
rules:
  - apiGroups: [""]
    resources: ["endpoints"]
    verbs: ["get", "list", "watch", "create", "update", "patch"]
---
kind: RoleBinding
apiVersion: rbac.authorization.k8s.io/v1
metadata:
  name: leader-locking-efs-provisioner
  namespace: efs-provisioner
subjects:
  - kind: ServiceAccount
    name: efs-provisioner
    # replace with namespace where provisioner is deployed
    namespace: efs-provisioner
roleRef:
  kind: Role
  name: leader-locking-efs-provisioner
  apiGroup: rbac.authorization.k8s.io
 
---
apiVersion: v1
kind: ServiceAccount
metadata:
  name: efs-provisioner
  namespace: efs-provisioner

---
apiVersion: v1
kind: ConfigMap
metadata:
  name: efs-provisioner
  namespace: efs-provisioner
data:
  file.system.id: {{ .Values.awsefsDnsName}}               
  aws.region: ap-south-1
  provisioner.name: example.com/aws-efs
  dns.name: ""
---
kind: Deployment
apiVersion: apps/v1
metadata:
  name: efs-provisioner
  namespace: efs-provisioner
spec:
  replicas: 1
  selector:
    matchLabels:
      app: efs-provisioner
  strategy:
    type: Recreate
  template:
    metadata:
      labels:
        app: efs-provisioner
    spec:
      serviceAccount: efs-provisioner
      containers:
        - name: efs-provisioner
          image: quay.io/external_storage/efs-provisioner:latest
          env:
            - name: FILE_SYSTEM_ID
              valueFrom:
                configMapKeyRef:
                  name: efs-provisioner
                  key: file.system.id
            - name: AWS_REGION
              valueFrom:
                configMapKeyRef:
                  name: efs-provisioner
                  key: aws.region
            - name: DNS_NAME
              valueFrom:
                configMapKeyRef:
                  name: efs-provisioner
                  key: dns.name
                  optional: true
            - name: PROVISIONER_NAME
              valueFrom:
                configMapKeyRef:
                  name: efs-provisioner
                  key: provisioner.name
          volumeMounts:
            - name: pv-volume
              mountPath: /persistentvolumes
      volumes:
        - name: pv-volume
          nfs:
            server: {{ .Values.awsefsDnsName}}         
---
kind: StorageClass
apiVersion: storage.k8s.io/v1
metadata:
  name: aws-efs
  namespace: efs-provisioner
provisioner: example.com/aws-efs

---
kind: PersistentVolumeClaim
apiVersion: v1
metadata:
  name: efs-1
  #namespace: efs-provisioner
spec:
  storageClassName: aws-efs
  accessModes:
    - ReadWriteMany
  resources:
    requests:
      storage: 1Gi
---	  
apiVersion: apps/v1
kind: Deployment
metadata:
  name: nginx-deployment
  labels:
    app: nginx
spec:
  replicas: 3
  selector:
    matchLabels:
      app: nginx
  template:
    metadata:
      labels:
        app: nginx
    spec:
      containers:
      - name: nginx
        image: sreeharshav/rollingupdate:v3
        ports:
        - containerPort: 80
        volumeMounts:
          - name: efs-pvc
            mountPath: /tmp/efsvol
      volumes:
         - name: efs-pvc
           persistentVolumeClaim:
              claimName: efs-1


root@ip-172-31-8-33:~# cd efs
root@ip-172-31-8-33:~/efs# vi values.yaml

awsefsDnsName: fs-bac6d76b.efs.ap-south-1.amazonaws.com





root@ip-172-31-8-33:~# helm package efs
Successfully packaged chart and saved it to: /root/efs-0.1.0.tgz
root@ip-172-31-8-33:~# helm lint efs
==> Linting efs
[INFO] Chart.yaml: icon is recommended
[ERROR] templates/: template: efs/templates/tests/test-connection.yaml:14:55: executing "efs/templates/tests/test-connection.yaml" at <.Values.service.port>: nil pointer evaluating interface {}.port

Error: 1 chart(s) linted, 1 chart(s) failed
root@ip-172-31-8-33:~# rm -f /root/efs-0.1.0.tgz
root@ip-172-31-8-33:~# rm -rf efs/templates/tests/


root@ip-172-31-8-33:~# cd efs
root@ip-172-31-8-33:~/efs# cd templates/
root@ip-172-31-8-33:~/efs/templates# ls
NOTES.txt     deployment.yaml  ingress.yaml  serviceaccount.yaml
_helpers.tpl  hpa.yaml         service.yaml
root@ip-172-31-8-33:~/efs/templates# rm -f serviceaccount.yaml service.yaml ingress.yaml hpa.yaml _helpers.tpl
root@ip-172-31-8-33:~/efs/templates# ll
total 20
drwxr-xr-x 2 root root 4096 Oct 19 11:24 ./
drwxr-xr-x 4 root root 4096 Oct 19 11:20 ../
-rw-r--r-- 1 root root 1731 Oct 19 10:58 NOTES.txt
-rw-r--r-- 1 root root 4343 Oct 19 11:12 deployment.yaml
root@ip-172-31-8-33:~/efs/templates#


root@ip-172-31-8-33:~# rm -f efs/templates/NOTES.txt
root@ip-172-31-8-33:~# helm lint efs
==> Linting efs
[INFO] Chart.yaml: icon is recommended

1 chart(s) linted, 0 chart(s) failed














